# Predecir_respuestas_de_tweets

proyecto para la materia `Text Mining`, `2021 FAMAF UNC`

Autor: `Joaqu√≠n Feltes`

Profesora: `Laura Alonso Alemany`

# Introducci√≥n

La idea principal es predecir cu√°ntas respuestas va a tener un tweet. Para esto se tom√≥ el approach de tarea de pretexto, usando la cantidad de respuestas de un tuit para generar una tag para el entrenamiento del modelo de predicci√≥n. Adem√°s, se va a utilizar el predictor de respuestas para ser agregado a un pipeline de generaci√≥n de respuestas a tuits. Este generador fue el trabajo final de [Lautaro Martinez](github.com/LMartinezEXEX/Generador_Contestaciones), un compa√±ero de la materia.

# Dataset

El dataset fue creado por Mariano Schmidt, para su tesis de Licenciatura: Explotando caracter√≠sticas contextuales para la detecci√≥n de posturas en Twitter en el marco de la vacunaci√≥n del COVID-19 en Argentina. Para pedir el dataset pueden pedirmelo por privado y tambi√©n dejo su [github](https://github.com/mschmidt4).

El dataset contiene 163.180 tweets en espa√±ol.

y tiene las siguientes caracter√≠sticas:

- created_at: contiene la fecha de env√≠o del tweet a la aplicaci√≥n.
- id_str: contiene el ID espec√≠fico del tweet.
- full_text: contiene el texto generado por el usuario del tweet.
- in_reply_to_status_id: de existir, contiene el ID del tweet al cual se est√° respondiendo.
- in_reply_to_user_id: de existir, contiene el ID del usuario del tweet al cual se est√° respondiendo.
- user.id: contiene el ID espec√≠fico del usuario que cre√≥ el tweet.

# Consideraciones y enfoques

En principio el trabajo de predecir cu√°ntas respuestas va a tener un tweet puede parecer sencillo, pero hay que tener en cuenta todos los distintos enfoques que son posibles para entrenar un modelo y todas las caracter√≠sticas que pueden agregarse a este para mejorar la predicci√≥n. Por esto se van a mostrar en este trabajo varios enfoques que han sido tomados, para el m√©todo de entrenamiento pero tambi√©n para la clasificaci√≥n de los tweets.

# Preproceso

Lo primero que se hace con el dataset es la eliminaci√≥n de arrobas, hashtags y urls. No hubo mucho trabajo de ingenier√≠a en esta parte del proyecto, ya que muchos compa√±eros que utilizaron el mismo dataset se concentraron en esto y por lo general hicieron un preproceso similar a este.

Luego se cuenta para cada tuit la cantidad de respuestas que posee, para agregarlo como una nueva caracter√≠stica 'ans'.

# Divisi√≥n del Dataset

Como ya se dijo, una parte importante del trabajo es la divisi√≥n en clases de las cantidades de respuestas, ya que esto es lo que se quiere predecir con el modelo final. Este proceso se llev√≥ a cabo en el archivo `Parseo_dataset.ipynb`

Primero para observar la distribuci√≥n de respuestas de los tweets del dataset tenemos el siguiente histograma:

## ![Histograma_discreto](./images/histograma_nans.png)

Aqu√≠ se puede ver un gran problema, hay una excesiva cantidad de tuits con 0 respuestas, y vemos como baja r√°pidamente la cantidad ya llegando a 4. Se tiene una distribuci√≥n exponencial inversa. Esto tiene mucho sentido, ya que es lo m√°s com√∫n que un tuit tenga 0 o 1 respuestas.

Por esta raz√≥n, se deben dividir en clases, para que cada clase tenga una cantidad de representantes similar a la de las otras. M√°s adelante se ver√° que si no se hace esto, los modelos tienden a aprender solo por la cantidad de representantes y una clase sobrerrepresentada va a hacer que se predigan muchos elementos para ella.

Se tom√≥ como par√°metro para la cantidad 6500 representantes, ya que hay aproximadamente esa cantidad con 2 respuestas y tambi√©n con 3 o m√°s. Se tomaron tambi√©n en cuenta divisiones con m√°s clases, separando en 3-4, 5-7 ,7-10 , +10, pero la cantidad de representantes era muy baja, y no se generaron resultados satisfactorios para esas divisiones. Otra divisi√≥n interesante, que no se ha llegado a explorar demasiado es la de separar entre 0 , pocas y muchas respuestas. O incluso es interesante la divisi√≥n entre ninguna o alguna respuesta.

Haciendo entonces la divisi√≥n por clases de [0, 1, 2, +3] tenemos la siguiente distribuci√≥n de respuestas:

## ![Histograma_clases1](./images/histograma_clases_1.png)

Ahora reducimos bastante el problema, ya que no tenemos infinitas cantidades de respuestas posibles, s√≥lo lo limitamos a 4 clases pensando que los tuits de m√°s de 2 respuestas van a pertenecer todos al mismo grupo.

Pero todav√≠a tenemos el problema de la sobrepoblaci√≥n de la clase del 0 y en menor medida, la del 1.

Lo que se decidi√≥ para que la cantidad de elementos sea aproximadamente la misma que las de las otras dos clases, fue dividir la clase del 0 en 18 subgrupos y la del 1 en 5 subgrupos, todos tomados al azar.

Con esto en mente, podemos ver como queda el histograma de las clases divididas exactamente con 1/18 de la clase del 0 y 1/5 de la del 1:

## ![Histograma_divididas](./images/histograma_divididas.png)

Vemos que esto deja los datos much√≠simo mejor, ahora todas las clases tienen aproximadamente la misma cantidad de elementos y no deber√≠a haber sesgo en el entrenamiento de datos.

Para la divisi√≥n en subgrupos, se tomaron hizo una divisi√≥n al azar con el framework de pandas, por lo que los resultados ense√±ados a continuaci√≥n no van a poder replicarse exactamente.

Por √∫ltimo se dividi√≥ todo el dataset para tener un 80% para entrenamiento, 10% develop y 10% para testeo final.

# Aproximaciones

## Bag of words con CountVectorizer

### Primer aproximaci√≥n

Esta parte del proceso se llev√≥ a cabo en el archivo `Entrenamiento.ipynb`

La primera aproximacion que se tomo fue utilizando [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) de sklearn para representar los tweets con "Bag of words" (bolsa de palabras). Esto significa que cada tweet va a ser un vector, donde cada dimensi√≥n es una palabra del vocabulario. Se tom√≥ como vocabulario las 15000 palabras m√°s recurrentes del dataset, para mayor eficiencia y facilidad en manejo de memoria pero tambi√©n para no incluir muchas palabras que ocurren solo una vez en todo el dataset y no van a aportar nada interesante.

La primera aproximaci√≥n que se hizo, que se puede ver en las primeras versiones de git del proyecto, fue con la divisi√≥n de clases [0,1,2-3,4-6,7-10,11-20,20+]. Esta fue tomada al azar, para tener una primera observaci√≥n de c√≥mo se comportaba el modelo. Aqu√≠ se puede ver la Matriz de confusi√≥n de esta aproximaci√≥n.

## ![Primer_test_BOW](./images/1er_test_BOW.png)

Se puede observar que a la mayor√≠a de elementos se les asign√≥ la clase de 0 respuestas, esto da un buen resultado general (68,4% de acierto), pero haciendo el an√°lisis de la matriz de confusi√≥n, se puede notar que la diagonal (donde se encuentran los resultados correctos) solo tiene la mayor√≠a de la fila en la clase del 0. Aca podemos ver con claridad el sesgo por la sobrepoblaci√≥n de la clase, el cual se podr√≠a discutir que no es tan malo, si en las muestras reales de tweets la mayor√≠a tiene esa cantidad de respuestas. Pero hay que recalcar que no se quiere conseguir un alto porcentaje de acierto prediciendo siempre que un tuit va a tener 0 respuestas, esto no nos genera ning√∫n aprendizaje ni aporta ning√∫n beneficio.

Luego la primer aproximaci√≥n que se hizo utilizando la divisi√≥n [0, 1, 2, +3] pero aun sin utilizar los subgrupos de 0 y 1, tuvo resultados similares al anterior, acumulandose las predicciones en el lado de 0 respuestas, pero teniendo los datos mucho m√°s compactos lo cual facilita su visualizaci√≥n. Algo a remarcar es que para este entrenamiento no se utiliz√≥ en su totalidad el dataset para entrenamiento, ya que saturan la memoria del Google colab. Se tomaron entonces los primeros 25000 tuits, que siguen representando una buena cantidad.

## ![Basic_BOW](./images/Basic_BOW.png)

### utilizando las subdivisiones de 0 y 1

Para que la predicci√≥n no se base en la cantidad de elementos, sino que se concentre en realmente el contenido del tweet, separamos la clase del 0 y del 1 en otros nuevos dataframes, los cuales est√°n marcados con subgrupos para ser entrenados por separado y tomar el promedio entre los resultados. Se corrieron las 90 combinaciones de subgrupos de clases, combinandolas con el resto de tweets. Luego se guardo un par de √≠ndices random para obtener la matriz de confusi√≥n:

## ![BOW_subdivisiones](./images/BOW_classes_10_2.png)

Lo primero que se puede notar, es que el porcentaje general baja abruptamente, cerca de un 24%. Pero ahora se puede decir que el modelo est√° realmente prediciendo por lo que ve en los vectores de los tweets, y no tanto en que clase tiene m√°s elementos. Vemos que la clase del 0 tiene ahora un poco m√°s de 50% de predicciones correctas, la del 1 un 30%, la del 2 es la peor, siendo su label real la que menos predijo el modelo (20%), y por √∫ltimo la clase de +3 con un 40 % de acierto. Se puede decir tambi√©n que al estar gran parte de los tweets con 0 bien representados (que es la clase con m√°s elementos de testeo) eso subi√≥ la estad√≠stica, pero se ve un gran avance en el resto de las clases para el peque√±o cambio que se hizo.

### Con las subdivisiones y clases discretas

Para analizar un poco mejor las cantidades de respuestas, sin depender de las clases que asignamos, se va a hacer un an√°lisis tomando como las clases los primeros 20 enteros.

## ![BOW_discreto](./images/BOW_discrete_1_1.png)

Podemos ver que el porcentaje general aumento por unos pocos puntos, pero nuevamente vemos una acumulacion grande en las clases de pocas respuestas, esta vez como los subgrupos de 0 y 1 y la clase de 2 tienen la misma cantidad de elementos, se puede ver que se repartieron la mayor√≠a de predicciones en estas columnas, y avanzando en la diagonal lejos de la esquina superior izquierda, podemos ver que todas las predicciones dan 0%. La clase del 20, tiene un poco m√°s de elementos, ya que acumula todos los tuits de 20 o m√°s respuestas, y tuvo un poco m√°s de representaci√≥n, pero igualmente su porcentaje de acierto fue menor al 10%.

Podemos observar en el siguiente histograma la cantidad de elementos que ten√≠a cada clase para el entrenamiento, lo cual nos explica porque las clases del medio no est√°n bien representadas.

## ![BOW_discreto_histograma](./images/histograma_bow_discreto.png)

Una de las razones por las que se tom√≥ esta aproximaci√≥n fue para ver si val√≠a la pena hacer una divisi√≥n de clases dependiendo de c√≥mo juntaba el modelo las respuestas si se observaban todas las clases juntas. Pero al tener tan pocos datos marcados con m√°s de 3 respuestas, es dif√≠cil hacer esta divisi√≥n y que de alg√∫n valor. Igualmente se intent√≥ hacer la siguiente aproximaci√≥n:

## ![BOW_0_1_mas](./images/0_1-2_mas.png)

Donde se dividi√≥ en 0, 1-2 y +3. Se puede ver que esta divisi√≥n no fue muy buena, probablemente porque la cantidad de elementos de la clase de 1-2 era el doble que de las otras hizo que sea sobrerrepresentada. Pero al haber dado un porcentaje tan bajo, no se decidi√≥ seguir investigando por esa rama.

## Embeddings utilizando fasttext

Para el uso de embeddings con fasttext se tom√≥ como ejemplo el trabajo de [Nazareno Garagiola](https://github.com/NazaGara/tm_seriesTV), otro compa√±ero de la materia. Se usaron embeddings con fasttext de twitter en espa√±ol `fasttext_spanish_twitter_100d`. Para conseguir estos embeddings pueden pedirlos a cualquiera de nosotros dos.

Para el proceso de embeddings se hacen algunos preprocesos extra, bastante similares a los que ya utilizamos.

Usamos la librer√≠a [pickle](https://docs.python.org/es/3/library/pickle.html) para guardar el preproceso y no hacerlo cada vez que corremos el c√≥digo.
¬°Importante! Esto guarda los tweets preprocesados en drive, y al ejecutarlo con las 90 clases, llega a ocupar cerca de 3GB.

### Primer aproximaci√≥n

La primer aproximaci√≥n usando las clases de [0, 1, 2, +3] pero sin utilizar los subgrupos de 0 y 1 tuvo resultados parecidos a su similar con BOW, con un porcentaje un poco mayor, pero tambi√©n con m√°s predicciones de la clase del 0, dejando la clase de 2 respuestas con solo una predicci√≥n que adem√°s fue incorrecta (era para un tuit con 1 respuesta).

## ![basic_emb](./images/1er_test_embeddings.png)

### utilizando las subdivisiones de 0 y 1

Cuando usamos las divisiones de las clases del 0 y el 1, perdemos unos puntos porcentuales del total(20%), pero ganamos bastante representaci√≥n en las clases m√°s peque√±as:

## ![emb_subdivisiones](./images/embedding_classes_14_5.png)

Tenemos un 62% de acierto en la clase del 0, 10% m√°s que lo que se ten√≠a en el m√©todo con BOW. La clase del 1 se ve poco representada, con un 18%, 12 puntos menos que lo que ten√≠a en BOW, y lo mismo pasa con la del 2, que vuelve a ser la que menos porcentaje tiene en su fila (tambi√©n 18%) pero por √∫ltimo la clase de +3 tiene un 47%, 7 puntos m√°s que lo que ten√≠a en BOW, por lo que con embeddings vemos que se representaron las clases de los extremos, lo cual tiene sentido.

### Con las subdivisiones y clases discretas

Nuevamente se prob√≥ usar las clases discretas, y se obtuvieron resultados muy parecidos a los de BOW. Que aunque suba el porcentaje de acierto general por unos pocos puntos, no vale la pena porque pierden representaci√≥n las clases del medio.

## ![emb_discreto](./images/embedding_classes_discrete_1_1.png)

## Conclusi√≥n

Como conclusi√≥n de esta etapa, podemos decir que la cantidad de representantes fue una gran influencia en las predicciones de cantidades de respuestas. Pero no hay que quedarse solo con eso, hay que apreciar el trabajo logrado para la divisi√≥n de clases, que como vimos comparando con otras, la divisi√≥n elegida fue bastante buena. Tambi√©n recalcar que el uso de embeddings mejoro el rendimiento, lo cual es importante para tener en cuenta.

Podemos ver en el siguiente boxplot la comparaci√≥n final de los m√©todos.

## ![boxplot](./images/Boxplot.png)

Se puede ver que el salto de utilizar embeddings es importante, y que a su vez los embeddings en clases discretas tienen bastante ventaja, pero como ya vimos en el an√°lisis un poco m√°s cualitativo del resultado de cada clase, es m√°s valorable tener las clases peque√±as bien representadas tambi√©n.

Por √∫ltimo para cerrar esta parte, hay que remarcar que se puede hacer mucha ingenier√≠a a los datos para exprimirlos mejor, usando por ejemplo bigramas o trigramas, DocVectorizer y muchos otros metodos de analisis de texto.

# Predicci√≥n de respuestas como parte de un Pipeline

Como se dijo anteriormente, se trabaj√≥ con el proyecto de [Lautaro Martinez](github.com/LMartinezEXEX/Generador_Contestaciones).

La idea principal es que con los modelos de generaci√≥n de respuestas, se haga un an√°lisis estas dependiendo cuantas respuestas predijo mi modelo que iba a tener el tweet. Por ejemplo, un tuit al que mi modelo predijo 0 respuestas, se espera que tenga una respuesta generada de menor calidad que a uno que se predijo +3.

Para esto, la idea era usar los 4 modelos de clusters entrenados que utiliza Lautaro, tomando los centroides de cada cluster. Con los centroides de cada cluster la idea es que se compare la distancia coseno a cada uno con el tuit al que se quiere generar la respuesta. Luego el que tenga menor distancia va a ser el cluster cuyo modelo pre entrenado se va a usar para generar la respuesta. Luego analizamos la cantidad de respuestas que predijo mi modelo y vemos la calidad de respuesta generada. Se puede agregar mi modelo al pipeline de Lautaro chequeando que la cantidad de respuestas predicha sea mayor a 0, ya que si es 0 no vale la pena que ese tuit sea contestado.

Por dificultades con el entrenamiento, no se hizo la parte de los centroides si no que se tom√≥ directamente el cluster 1 y se hizo la parte del an√°lisis de calidad de respuesta.

Tomamos los siguientes tweets con su cantidad de respuestas y la predicci√≥n de este valor:

```
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
porque el pami no lo maneja un jubilado todos tienen sindicatos pq el pami no, digo por ahi puede ser una solucion que manejen su propia plata estoy delirando sorry
cantidad de respuestas:   0
preddicion con el modelo: 2
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
No te estoy diciendo nada a vos. Te sigo hace tiempo y s√© que siempre ped√≠s transparencia, no s√≥lo con las vacunas. Simplemente digo que no se puede vivir permanentemente con las libertades restringidas y que hay que tener cuidado al decir esto importa m√°s que aquello.
cantidad de respuestas:   0
preddicion con el modelo: 2
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Y tenemos que aplaudir?
cantidad de respuestas:   0
preddicion con el modelo: 0
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
.

.
cantidad de respuestas:   0
preddicion con el modelo: 0
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Te repito. REPELOTUDO, la ANMAT solo recibi√≥ datos de un cortepreliminar.  O sea de una menor cantidad de casos, no recibi√≥ el informe final del estudio.
Veo que no le√≠ste el informe de ANMAT. No habla de cantidad de ensayos, ni de porcentajes ni resultados finales.
cantidad de respuestas:   2
preddicion con el modelo: 2
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
no mucho todav√≠a
cantidad de respuestas:   1
preddicion con el modelo: 0
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Gracias!!!!!!‚ù§
cantidad de respuestas:   0
predicci√≥n con el modelo: 0
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Encima es profesor. Mamita
cantidad de respuestas:   0
predicci√≥n con el modelo: 0
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
che, que ganas de probar con Ernestito un litro de di√≥xido de cloro intravenoso
cantidad de respuestas:   0
predicci√≥n con el modelo: 0
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Y si hay vos no lo vas a decir....ya perdimos la inocencia mira si les vamos a creer ü§¢
cantidad de respuestas:   0
predicci√≥n con el modelo: 0
```

Los tuits n√∫mero 1, 2 y 5 fueron los que el modelo predijo que iban a tener 2 respuestas, para el resto se predijeron 0. Veamos las respuestas de estos:

1 - Tweet:

    porque el pami no lo maneja un jubilado todos tienen sindicatos pq el pami no, digo por ahi puede ser una soluci√≥n que manejen su propia plata estoy delirando sorry

Respuesta:

    @spitta1969 Cu√°ntos culos habr√° lamido este inutil para llegar a un puesto donde debe ganar bastante?

Vemos que el primer tuit hace una pregunta sobre el pami, mientras que la respuesta que se genera es un ataque que poco esta relacionada a la pregunta.

2 - Tweet:

    No te estoy diciendo nada a vos. Te sigo hace tiempo y s√© que siempre ped√≠s transparencia, no s√≥lo con las vacunas. Simplemente digo que no se puede vivir permanentemente con las libertades restringidas y que hay que tener cuidado al decir esto importa m√°s que aquello.

Respuesta:

    @rquiroga777 Me parece que en el fondo todos sabemos que la cuarentena total ya es inevitable. Me parece que las restricciones son el pre√°mbulo.

En el segundo tuit, se genera algo muy interesante, habla de manera bastante educada sobre las "libertades restringidas" refiri√©ndose probablemente a la cuarentena. Mientras que su respuesta generada, dice que la cuarentena total es inevitable y que las restricciones son el pre√°mbulo de esta.

Es interesante marcar que aunque el modelo hab√≠a predicho 2 respuestas, el tuit original no ten√≠a ninguna, pero tiene mucho sentido que por la manera en que est√° escrito si tuviese. Y vimos que la respuesta generada tiene mucho sentido.

5 - Tweet:

    Te repito. REPELOTUDO, la ANMAT solo recibi√≥ datos de un cortepreliminar. O sea de una menor cantidad de casos, no recibi√≥ el informe final del estudio.
    Veo que no le√≠ste el informe de ANMAT. No habla de cantidad de ensayos, ni de porcentajes ni resultados finales.

Respuesta:

    @NicoOlsze Yo recuerdo y tengo guardados los memes d√≥nde ped√≠an q vacunen a los pol√≠ticos primero. No hay poronga q les venga bien. Lastima q no tengo seguidores. Jajaja

Por ultimo en el tercer tuit, habla muy violentamente sobre informes del ANMAT, seguramente de las vacunas, diciendo que estas no est√°n aprobadas. Y la respuesta que se genera habla diciendo que la gente ped√≠a que los pol√≠ticos se vacunen primero y responde de manera un poco violenta tambi√©n de que nada les viene bien. Se nota que son conversaciones diferentes, puesto que el primero habla de que no quiere que les pongan vacunas y el segundo le responde a alguien que probablemente se queja de que los pol√≠ticos se vacunaron primero.

Igualmente, el tema general es bastante acertado, y sin prestar atenci√≥n puede parecer una conversaci√≥n normal de twitter.

Observando el resto de tuits, se nota que el modelo no pudo generar respuestas muy relacionadas al tema del tuit al que se contesta, lo cual era de esperar ya que nuestro modelo predijo que no iba a tener respuestas

Cabe remarcar que el tuit "no mucho todav√≠a" se predijo con 0 respuestas a pesar que tiene 1 realmente. Esto indica que a pesar de que sea un fallo en la estad√≠stica, es una respuesta que tiene sentido ya que no hay mucho que contestar a este tweet, lo cual es alentador para el modelo. (Algo similar ocurri√≥ con el tweet n√∫mero 2 mostrado anteriormente).
