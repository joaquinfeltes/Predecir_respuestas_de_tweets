{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Parseo_dataset.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hfur3Bl8CyHU"
      },
      "source": [
        "import csv\n",
        "import re\n",
        "import pandas as pd\n",
        "#None para visualizar todas las columnas, False para la version recortada\n",
        "pd.set_option(\"display.max_columns\", None)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMlCzQP2wJQ5"
      },
      "source": [
        "#Parseo de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udcEegN1Cu9q",
        "outputId": "26b4b5bc-4cd9-49bc-c67f-2bca7d8d7c2d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "drive_path = '/content/drive/MyDrive/Mineria/'\n",
        "filename = \"dataset_pln_20211019.csv\""
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AspucXy7DRVx",
        "outputId": "deec8a0a-7d94-4b4f-d78a-9122210d9c6a"
      },
      "source": [
        "# Se parsean los datos manualmente y no con pandas,\n",
        "# porque es mas facil para agregar las cantidades de respuestas de cada tuit\n",
        "is_first_cell = True\n",
        "tweets_dicc = {}\n",
        "\n",
        "with open(drive_path+filename, mode='r') as csv_file:\n",
        "  csv_reader = csv.DictReader(csv_file)\n",
        "  for row in csv_reader:\n",
        "    if is_first_cell:\n",
        "      print(f'Column names are {\", \".join(row)}')\n",
        "      is_first_cell = False\n",
        "\n",
        "    id_str = row[\"id_str\"]\n",
        "    in_reply_to_status_id = row[\"in_reply_to_status_id\"]\n",
        "    full_text = row[\"full_text\"]\n",
        "    \n",
        "    created_at = row[\"created_at\"]\n",
        "    in_reply_to_user_id = row[\"in_reply_to_user_id\"]\n",
        "    user_id = row[\"user_id\"]\n",
        "\n",
        "    # Eliminar hashtags, menciones y urls\n",
        "    full_text = re.sub('#\\w+ ', '', full_text)\n",
        "    full_text = re.sub('@\\w+ ', '', full_text)\n",
        "    full_text = re.sub(r'http\\S+', '', full_text)\n",
        "    row[\"full_text\"] =full_text\n",
        "\n",
        "\n",
        "    # Contar las respuestas y ponerlo en una nueva columna\n",
        "\n",
        "    # si ya existe un tweet de ese id, es porque se creo' porque tenia una respuesta\n",
        "    if tweets_dicc.get(id_str):\n",
        "      tweets_dicc[id_str].update(row)\n",
        "    # si es la primera vez que lo vimos, creamos el dict por completo\n",
        "    else:\n",
        "      tweets_dicc[id_str] = {**{\"ans\": 0}, **row }\n",
        "\n",
        "    #si es respuesta de x\n",
        "    if in_reply_to_status_id:\n",
        "      #si es la primera respuesta que recibe x\n",
        "      if not tweets_dicc.get(in_reply_to_status_id,{}).get(\"ans\",0):\n",
        "        #si todavia no vimos a x\n",
        "        if not tweets_dicc.get(in_reply_to_status_id, {}).get(\"id_str\"):\n",
        "          tweets_dicc[in_reply_to_status_id] = {\"ans\": 1}\n",
        "        #si ya vimos a x\n",
        "        else:\n",
        "          tweets_dicc[in_reply_to_status_id].update({\"ans\": 1})\n",
        "      #si x ya tuvo otra respuesta\n",
        "      else:\n",
        "        tweets_dicc[in_reply_to_status_id][\"ans\"] +=1\n",
        "\n",
        "    # print(created_at, id_str, full_text, in_reply_to_status_id, in_reply_to_user_id, user_id)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column names are created_at, id_str, full_text, in_reply_to_status_id, in_reply_to_user_id, user_id\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMj160WbCyRl"
      },
      "source": [
        "#Borrar los tuits que no tienen texto en la bd\n",
        "#i y j son para contar la cantidad de tuits que hay con y sin texto\n",
        "dic_ans_num = {}\n",
        "tw_wo_text = []\n",
        "# i = 0\n",
        "# j = 0\n",
        "for tw_id in tweets_dicc:\n",
        "  # print(tweets_dicc[tw_id].get(\"id_str\"), tweets_dicc[tw_id].get(\"ans\"))\n",
        "  # j+=1\n",
        "  id = tweets_dicc[tw_id].get(\"id_str\")\n",
        "  ans = tweets_dicc[tw_id].get(\"ans\")\n",
        "  dic_ans_num[ans] = dic_ans_num.get(ans,0)+1\n",
        "  \n",
        "  #hay i (358) tweets de 163441 que tienen respuesta, pero no tienen texto en la bd\n",
        "  if not id :\n",
        "    tw_wo_text.append(tw_id)\n",
        "    # i +=1\n",
        "    # print(id, tw_id, ans)\n",
        "\n",
        "# print(len(tweets_dicc))\n",
        "#borrando del dicc los tw sin texo\n",
        "for id in tw_wo_text:\n",
        "  del tweets_dicc[id]\n",
        "# print(i, j, j-i)\n",
        "# print(len(tweets_dicc))\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEp-EJbJCybU"
      },
      "source": [
        "#Agregar los tags a los tuits segun su cantidad de respuestas\n",
        "dic_ans_class = {\"0\":0,\n",
        "                 \"1\":0,\n",
        "                 \"2-3\":0,\n",
        "                 \"4-6\":0,\n",
        "                 \"7-10\":0,\n",
        "                 \"11-20\":0,\n",
        "                 \"20+\":0}\n",
        "\n",
        "for tw_id in tweets_dicc:\n",
        "  ans = tweets_dicc[tw_id].get(\"ans\")\n",
        "  if ans ==0:\n",
        "    dic_ans_class[\"0\"]+=1\n",
        "    tweets_dicc[tw_id][\"class\"] = \"0\"\n",
        "  elif ans <=1:\n",
        "    dic_ans_class[\"1\"]+=1\n",
        "    tweets_dicc[tw_id][\"class\"] = \"1\"\n",
        "  elif ans <=3:\n",
        "    dic_ans_class[\"2-3\"]+=1\n",
        "    tweets_dicc[tw_id][\"class\"] = \"2-3\"\n",
        "  elif ans <=6:\n",
        "    dic_ans_class[\"4-6\"]+=1\n",
        "    tweets_dicc[tw_id][\"class\"] = \"4-6\"\n",
        "  elif ans <=10:\n",
        "    dic_ans_class[\"7-10\"]+=1\n",
        "    tweets_dicc[tw_id][\"class\"] = \"7-10\"\n",
        "  elif ans <=20:\n",
        "    dic_ans_class[\"11-20\"]+=1\n",
        "    tweets_dicc[tw_id][\"class\"] = \"11-20\"\n",
        "  else:\n",
        "    dic_ans_class[\"20+\"]+=1\n",
        "    tweets_dicc[tw_id][\"class\"] = \"20+\"\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnzE8Q1RCymf"
      },
      "source": [
        "#paso los tuits a un dataframe para dividirlo mas facilmente\n",
        "tweets_df = pd.DataFrame.from_dict(tweets_dicc, orient='index')\n",
        "# print(tweets_df)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRuJcdhKtlqX"
      },
      "source": [
        "#Dividir el df en 80 10 10\n",
        "#training_df tiene el 80%\n",
        "training_df = tweets_df.sample(frac = 0.80)\n",
        "#rest tiene el 20%\n",
        "rest = tweets_df.drop(training_df.index)\n",
        "\n",
        "#develop tiene el 10% (50% del 20% de rest)\n",
        "develop_df = rest.sample(frac = 0.50) \n",
        "\n",
        "#test tiene el 10% (50% del 20% de rest)\n",
        "test_df =  rest.drop(develop_df.index)\n",
        "\n",
        "# print(len(training_df), len(develop_df), len(test_df))\n",
        "# print(len(training_df)+ len(develop_df)+ len(test_df))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dN0D4oZxCpE"
      },
      "source": [
        "training_df.to_csv(drive_path+'training_df.csv', index=False)\n",
        "develop_df.to_csv(drive_path+'develop_df.csv', index=False)\n",
        "test_df.to_csv(drive_path+'test_df.csv', index=False)\n"
      ],
      "execution_count": 19,
      "outputs": []
    }
  ]
}